{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad60b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603c239",
   "metadata": {},
   "source": [
    "1. Sample text (Longer to see the effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63cd1f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The concept of Retrieval-Augmented Generation (RAG) was introduced to solve \n",
    "the problem of LLM hallucinations. By providing a 'source of truth', \n",
    "the model doesn't have to rely only on its internal weights. \n",
    "This is critical for industries like medicine and law where accuracy is \n",
    "not optional, but a strict requirement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3cfb0",
   "metadata": {},
   "source": [
    "2. Initialize the Token Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86bd2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = TokenTextSplitter(\n",
    "    chunk_size = 20,\n",
    "    chunk_overlap = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bc01837",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399896e",
   "metadata": {},
   "source": [
    "3. Output the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11d94acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Chunk 1 ---\n",
      "\n",
      "The concept of Retrieval-Augmented Generation (RAG) was introduced to solve \n",
      "\n",
      "--- Chunk 2 ---\n",
      " introduced to solve \n",
      "the problem of LLM hallucinations. By providing a 'source of truth',\n",
      "--- Chunk 3 ---\n",
      " 'source of truth', \n",
      "the model doesn't have to rely only on its internal weights.\n",
      "--- Chunk 4 ---\n",
      " on its internal weights. \n",
      "This is critical for industries like medicine and law where accuracy is \n",
      "--- Chunk 5 ---\n",
      " law where accuracy is \n",
      "not optional, but a strict requirement.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"--- Chunk {i+1} ---\")\n",
    "    print(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
