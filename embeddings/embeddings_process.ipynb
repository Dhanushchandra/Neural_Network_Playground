{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ff63c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a64fa7",
   "metadata": {},
   "source": [
    "1. THE KNOWLEDGE BASE (Our \"External Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d49d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Our office is located in Bangalore, India.\",\n",
    "    \"The company was founded in 2021 by a group of engineers.\",\n",
    "    \"We provide AI solutions for healthcare and finance.\",\n",
    "    \"Our CEO is Sarah Jenkins, a former data scientist.\",\n",
    "    \"Working hours are from 9 AM to 6 PM, Monday to Friday.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968649c",
   "metadata": {},
   "source": [
    "2. INGESTION: Load a model to turn text into numbers (Embeddings)\n",
    "This model converts a sentence into a vector of 384 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d133fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdde81559d94560ba96af407bcaab57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3b19d73a4e4937a394592c0665afb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90eae754f214299a23f4e83c083ac25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2fb47a2a2944215a18607576b9ea4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11418a8431d44b990d799e1998c2c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9da3c8f07d434dae5f4a2cd697e428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3732ba17f90940b784d91f16c74ad838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee0f739c5494c999e011ac8347f7537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fd9b285683459bbbe094cc1f099ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc416b4ef5c4a6a82870d487f9e1a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32018d0c53844fd39f742d63ea8eb273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08132b2f",
   "metadata": {},
   "source": [
    "3. RETRIEVAL: The user asks a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80434a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Where is the company based and who is the CEO?\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ca759",
   "metadata": {},
   "source": [
    "Calculate 'Cosine Similarity' (how close the query is to each document)\n",
    "Formula: dot_product(A, B) / (norm(A) * norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405a2650",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = np.dot(doc_embeddings,query_embedding.T).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783b3e62",
   "metadata": {},
   "source": [
    "Get the indices of the top 2 most relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef98649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = np.argsort(similarities)[-2:][::-True]\n",
    "retrieved_context = [documents[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cad176",
   "metadata": {},
   "source": [
    "4. GENERATION: Prepare the prompt for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72652c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVED CONTEXT ---\n",
      "Our CEO is Sarah Jenkins, a former data scientist.\n",
      "The company was founded in 2021 by a group of engineers.\n",
      "\n",
      "--- FINAL PROMPT FOR LLM ---\n",
      "\n",
      "Answer the question based ONLY on the context provided below.\n",
      "Context:\n",
      "Our CEO is Sarah Jenkins, a former data scientist.\n",
      "The company was founded in 2021 by a group of engineers.\n",
      "\n",
      "Question: Where is the company based and who is the CEO?\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_text = \"\\n\".join(retrieved_context)\n",
    "final_prompt = f\"\"\"\n",
    "Answer the question based ONLY on the context provided below.\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(f\"--- RETRIEVED CONTEXT ---\\n{context_text}\\n\")\n",
    "print(f\"--- FINAL PROMPT FOR LLM ---\\n{final_prompt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
